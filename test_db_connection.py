```python
# ÙØ§ÛŒÙ„: test_db_connection.py
import sqlite3
import pandas as pd
from pathlib import Path

def test_connection():
    db_path = Path("./data/quantum_trading.db")  # Ù…Ø³ÛŒØ± Ø¯ÛŒØªØ§Ø¨ÛŒØ³
    
    try:
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # 1. ØªØ³Øª Ø®ÙˆØ§Ù†Ø¯Ù† Ú©Ù†Ø¯Ù„â€ŒÙ‡Ø§
        cursor.execute("SELECT COUNT(*) as total_candles FROM candles_1m")
        candles_count = cursor.fetchone()[0]
        
        # 2. ØªØ³Øª Ø®ÙˆØ§Ù†Ø¯Ù† Ù†Ù‡Ù†Ú¯â€ŒÙ‡Ø§
        cursor.execute("SELECT COUNT(*) as total_whales FROM whale_movements")
        whales_count = cursor.fetchone()[0]
        
        # 3. Ù„ÛŒØ³Øª Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯
        cursor.execute("SELECT DISTINCT symbol FROM candles_1m LIMIT 5")
        symbols = cursor.fetchall()
        
        conn.close()
        
        print(f"""
        âœ… Ø§ØªØµØ§Ù„ Ø¨Ù‡ Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ù…ÙˆÙÙ‚ÛŒØªâ€ŒØ¢Ù…ÛŒØ² Ø¨ÙˆØ¯:
        
        ğŸ“Š Ø¢Ù…Ø§Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³:
        â€¢ ØªØ¹Ø¯Ø§Ø¯ Ú©Ù†Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡â€ŒØ´Ø¯Ù‡: {candles_count:,}
        â€¢ ØªØ¹Ø¯Ø§Ø¯ Ø­Ø±Ú©Ø§Øª Ù†Ù‡Ù†Ú¯ Ø«Ø¨Øªâ€ŒØ´Ø¯Ù‡: {whales_count:,}
        â€¢ Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯: {[s[0] for s in symbols]}
        
        ğŸ¯ Ø³ÛŒØ³ØªÙ… Ø¢Ù…Ø§Ø¯Ù‡ ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø§Ø³Øª.
        """)
        
        return True
        
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§ØªØµØ§Ù„ Ø¨Ù‡ Ø¯ÛŒØªØ§Ø¨ÛŒØ³: {e}")
        return False

if __name__ == "__main__":
    test_connection()
```

ğŸ“¦ Ú©Ø¯ Ú©Ø§Ù…Ù„ Ù…ÙˆØªÙˆØ± Ú©Ø´Ù Ø§Ù„Ú¯Ùˆ (ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡ Ø¨Ø§ Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ø´Ù…Ø§):

Ù¾Ø³ Ø§Ø² ØªØ£ÛŒÛŒØ¯ Ø§ØªØµØ§Ù„ØŒ Ø§ÛŒÙ† Ù…ÙˆØªÙˆØ± Ø§ØµÙ„ÛŒ Ø±Ø§ Ø¯Ø± Ú©Ù†Ø§Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ù‚Ø±Ø§Ø± Ø¨Ø¯Ù‡. Ø§ÛŒÙ† Ú©Ø¯ Ø¨Ù‡ Ø·ÙˆØ± Ù…Ø³ØªÙ‚ÛŒÙ… Ø§Ø² Ø¬Ø¯Ø§ÙˆÙ„ candles_1m Ùˆ whale_movements ØªÙˆ Ø¯Ø§Ø¯Ù‡ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù†Ø¯:

```python
"""
ğŸ§  GALACTIC PATTERN DISCOVERY ENGINE - PRODUCTION v1.0
Ø§ØªØµØ§Ù„ Ù…Ø³ØªÙ‚ÛŒÙ… Ø¨Ù‡ Ø¯ÛŒØªØ§Ø¨ÛŒØ³ ÙˆØ§Ù‚Ø¹ÛŒ Ú©Ø§Ø±Ø¨Ø±
"""

import sqlite3
import numpy as np
import pandas as pd
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import json
import hashlib
import asyncio
import logging

# ==================== CONFIGURATION ====================
DB_PATH = Path("./data/quantum_trading.db")  # Ù…Ø³ÛŒØ± Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ø§ØµÙ„ÛŒ Ø´Ù…Ø§
SYMBOL = "BTCUSDT"  # Ù†Ù…Ø§Ø¯ Ù‡Ø¯Ù Ø¨Ø±Ø§ÛŒ Ú©Ø´Ù Ø§Ù„Ú¯Ùˆ

class RealDataPatternEngine:
    """Ù…ÙˆØªÙˆØ± Ú©Ø´Ù Ø§Ù„Ú¯Ùˆ Ø¨Ø§ Ø§ØªØµØ§Ù„ Ù…Ø³ØªÙ‚ÛŒÙ… Ø¨Ù‡ Ø¯ÛŒØªØ§Ø¨ÛŒØ³ ÙˆØ§Ù‚Ø¹ÛŒ"""
    
    def __init__(self, db_path: Path = DB_PATH):
        self.db_path = db_path
        self.conn = None
        self.setup_logging()
        
        # Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ú©Ø´Ù
        self.config = {
            'min_candles_for_analysis': 5000,
            'discovery_lookback_days': 30,
            'min_pattern_confidence': 0.65,
            'required_win_rate': 0.55,
            'max_drawdown_limit': 0.15,
            'test_period_days': 7
        }
        
    def setup_logging(self):
        """ØªÙ†Ø¸ÛŒÙ… Ø³ÛŒØ³ØªÙ… Ù„Ø§Ú¯â€ŒÚ¯ÛŒØ±ÛŒ"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('pattern_discovery.log'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
    
    # ==================== DATABASE CONNECTION ====================
    
    def connect_to_database(self) -> bool:
        """Ø§ØªØµØ§Ù„ Ø¨Ù‡ Ø¯ÛŒØªØ§Ø¨ÛŒØ³ SQLite"""
        try:
            self.conn = sqlite3.connect(self.db_path)
            self.conn.row_factory = sqlite3.Row  # Ø¨Ø±Ø§ÛŒ Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ Ø¨Ø§ Ù†Ø§Ù…
            self.logger.info(f"âœ… Ù…ØªØµÙ„ Ø¨Ù‡ Ø¯ÛŒØªØ§Ø¨ÛŒØ³: {self.db_path}")
            return True
        except Exception as e:
            self.logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§ØªØµØ§Ù„ Ø¨Ù‡ Ø¯ÛŒØªØ§Ø¨ÛŒØ³: {e}")
            return False
    
    def disconnect(self):
        """Ù‚Ø·Ø¹ Ø§ØªØµØ§Ù„ Ø§Ø² Ø¯ÛŒØªØ§Ø¨ÛŒØ³"""
        if self.conn:
            self.conn.close()
            self.logger.info("âœ… Ø§ØªØµØ§Ù„ Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ø¨Ø³ØªÙ‡ Ø´Ø¯")
    
    # ==================== REAL DATA FETCHING ====================
    
    def fetch_candle_data(self, symbol: str = SYMBOL, days: int = 30) -> pd.DataFrame:
        """Ø®ÙˆØ§Ù†Ø¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú©Ù†Ø¯Ù„ ÙˆØ§Ù‚Ø¹ÛŒ Ø§Ø² Ø¯ÛŒØªØ§Ø¨ÛŒØ³"""
        query = """
        SELECT 
            timestamp,
            open,
            high,
            low,
            close,
            volume,
            oi,
            funding_rate,
            buy_liq,
            sell_liq
        FROM candles_1m 
        WHERE symbol = ?
        AND timestamp >= datetime('now', '-' || ? || ' days')
        ORDER BY timestamp ASC
        """
        
        try:
            df = pd.read_sql_query(
                query, 
                self.conn, 
                params=(symbol, days)
            )
            
            # ØªØ¨Ø¯ÛŒÙ„ timestamp Ø¨Ù‡ datetime
            df['timestamp'] = pd.to_datetime(df['timestamp'])
            
            # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§ÛŒ Ù¾Ø§ÛŒÙ‡
            df['returns'] = df['close'].pct_change()
            df['volume_ma'] = df['volume'].rolling(20).mean()
            df['volatility'] = df['returns'].rolling(50).std()
            
            self.logger.info(f"ğŸ“¥ {len(df)} Ú©Ù†Ø¯Ù„ ÙˆØ§Ù‚Ø¹ÛŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯ (Ù†Ù…Ø§Ø¯: {symbol})")
            return df
            
        except Exception as e:
            self.logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø®ÙˆØ§Ù†Ø¯Ù† Ú©Ù†Ø¯Ù„â€ŒÙ‡Ø§: {e}")
            return pd.DataFrame()
    
    def fetch_whale_data(self, symbol: str = SYMBOL, days: int = 30) -> pd.DataFrame:
        """Ø®ÙˆØ§Ù†Ø¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ù‡Ù†Ú¯ ÙˆØ§Ù‚Ø¹ÛŒ Ø§Ø² Ø¯ÛŒØªØ§Ø¨ÛŒØ³"""
        query = """
        SELECT 
            timestamp,
            size,
            direction,
            confidence,
            exchange
        FROM whale_movements 
        WHERE symbol = ?
        AND timestamp >= datetime('now', '-' || ? || ' days')
        ORDER BY timestamp ASC
        """
        
        try:
            df = pd.read_sql_query(
                query, 
                self.conn, 
                params=(symbol, days)
            )
            
            if not df.empty:
                df['timestamp'] = pd.to_datetime(df['timestamp'])
                self.logger.info(f"ğŸ‹ {len(df)} Ø­Ø±Ú©Øª Ù†Ù‡Ù†Ú¯ ÙˆØ§Ù‚Ø¹ÛŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯")
            else:
                self.logger.warning("âš ï¸ Ø¯Ø§Ø¯Ù‡ Ù†Ù‡Ù†Ú¯ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ ÛŒØ§ÙØª Ù†Ø´Ø¯")
            
            return df
            
        except Exception as e:
            self.logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø®ÙˆØ§Ù†Ø¯Ù† Ø¯Ø§Ø¯Ù‡ Ù†Ù‡Ù†Ú¯â€ŒÙ‡Ø§: {e}")
            return pd.DataFrame()
    
    # ==================== PATTERN DISCOVERY CORE ====================
    
    def discover_price_volume_patterns(self, df: pd.DataFrame) -> List[Dict]:
        """Ú©Ø´Ù Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ù‚ÛŒÙ…Øª-Ø­Ø¬Ù…"""
        patterns = []
        
        if len(df) < 100:
            return patterns
        
        try:
            # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ù‡Ù…
            correlations = {
                'volume_price': df['volume'].corr(df['close']),
                'oi_price': df['oi'].corr(df['close']) if 'oi' in df.columns else 0,
                'volume_returns': df['volume'].corr(df['returns'].abs()),
                'funding_returns': df['funding_rate'].corr(df['returns']) if 'funding_rate' in df.columns else 0
            }
            
            # Ø§Ù„Ú¯ÙˆÛŒ Ø­Ø¬Ù… Ø³Ù†Ú¯ÛŒÙ† + Ø­Ø±Ú©Øª Ù‚ÛŒÙ…Øª (Ù¾Ø§Ù…Ù¾)
            volume_spike_threshold = df['volume_ma'].mean() * 2
            df['volume_spike'] = df['volume'] > volume_spike_threshold
            df['price_up_5min'] = df['close'].pct_change(5) > 0.002  # 0.2% Ø±Ø´Ø¯ Ø¯Ø± 5 Ø¯Ù‚ÛŒÙ‚Ù‡
            
            pump_patterns = df[df['volume_spike'] & df['price_up_5min']]
            
            if len(pump_patterns) > 3:
                pattern = {
                    'id': 'VOL_PUMP_001',
                    'name': 'Ø§Ù„Ú¯ÙˆÛŒ Ù¾Ø§Ù…Ù¾ Ø­Ø¬Ù…ÛŒ',
                    'condition': 'volume > MA(volume,20)*2 AND price_increase_5min > 0.2%',
                    'occurrences': len(pump_patterns),
                    'avg_price_change': (pump_patterns['close'].pct_change(10).mean() * 100),
                    'confidence': min(len(pump_patterns) / 50, 0.9),
                    'timeframe': '5m',
                    'action': 'BUY'
                }
                patterns.append(pattern)
            
            # Ø§Ù„Ú¯ÙˆÛŒ ÙˆØ§Ú¯Ø±Ø§ÛŒÛŒ Ø­Ø¬Ù…-Ù‚ÛŒÙ…Øª (Ø¶Ø¹Ù Ø±ÙˆÙ†Ø¯)
            if len(df) > 100:
                df['price_high'] = df['close'].rolling(20).max()
                df['volume_low'] = df['volume'].rolling(20).min()
                
                divergence_patterns = df[(df['price'] == df['price_high']) & 
                                        (df['volume'] == df['volume_low'])]
                
                if len(divergence_patterns) > 2:
                    pattern = {
                        'id': 'VOL_DIVERGENCE_001',
                        'name': 'ÙˆØ§Ú¯Ø±Ø§ÛŒÛŒ Ø­Ø¬Ù…-Ù‚ÛŒÙ…Øª',
                        'condition': 'price = 20_period_high AND volume = 20_period_low',
                        'occurrences': len(divergence_patterns),
                        'avg_reversal': 0,  # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´ÙˆØ¯
                        'confidence': min(len(divergence_patterns) / 30, 0.8),
                        'timeframe': '15m',
                        'action': 'SELL'
                    }
                    patterns.append(pattern)
            
            return patterns
            
        except Exception as e:
            self.logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ú©Ø´Ù Ø§Ù„Ú¯ÙˆÙ‡Ø§: {e}")
            return patterns
    
    def discover_whale_patterns(self, price_df: pd.DataFrame, whale_df: pd.DataFrame) -> List[Dict]:
        """Ú©Ø´Ù Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø· Ø¨Ø§ Ø­Ø±Ú©Øª Ù†Ù‡Ù†Ú¯â€ŒÙ‡Ø§"""
        patterns = []
        
        if whale_df.empty:
            return patterns
        
        try:
            # Ø§Ø¯ØºØ§Ù… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù‚ÛŒÙ…Øª Ùˆ Ù†Ù‡Ù†Ú¯ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø²Ù…Ø§Ù†
            whale_df['timestamp_rounded'] = whale_df['timestamp'].dt.floor('5min')
            price_df['timestamp_rounded'] = price_df['timestamp'].dt.floor('5min')
            
            merged = pd.merge(
                price_df[['timestamp_rounded', 'close', 'returns']],
                whale_df.groupby('timestamp_rounded').agg({
                    'size': 'sum',
                    'direction': lambda x: list(x)
                }).reset_index(),
                on='timestamp_rounded',
                how='left'
            )
            
            # Ø§Ù„Ú¯ÙˆÛŒ Ù†Ù‡Ù†Ú¯ Ø®Ø±ÛŒØ¯Ø§Ø± + Ø­Ø±Ú©Øª ØµØ¹ÙˆØ¯ÛŒ
            big_buy_events = merged[
                (merged['size'] > merged['size'].quantile(0.75)) & 
                (merged['direction'].apply(lambda x: 'exchange_in' in str(x) if x else False))
            ]
            
            if len(big_buy_events) > 2:
                # Ø¨Ø±Ø±Ø³ÛŒ Ø­Ø±Ú©Øª Ù‚ÛŒÙ…Øª Ù¾Ø³ Ø§Ø² ÙˆØ±ÙˆØ¯ Ù†Ù‡Ù†Ú¯
                forward_returns = []
                for idx in big_buy_events.index:
                    if idx + 10 < len(price_df):
                        ret = price_df.iloc[idx + 10]['close'] / price_df.iloc[idx]['close'] - 1
                        forward_returns.append(ret)
                
                if forward_returns:
                    avg_return = np.mean(forward_returns) * 100
                    win_rate = sum(1 for r in forward_returns if r > 0) / len(forward_returns)
                    
                    if win_rate > self.config['required_win_rate']:
                        pattern = {
                            'id': 'WHALE_BUY_001',
                            'name': 'ÙˆØ±ÙˆØ¯ Ù†Ù‡Ù†Ú¯ Ø®Ø±ÛŒØ¯Ø§Ø±',
                            'condition': 'whale_inflow > 75_percentile AND direction = exchange_in',
                            'occurrences': len(big_buy_events),
                            'avg_return': avg_return,
                            'win_rate': win_rate,
                            'confidence': min(win_rate * 0.8, 0.85),
                            'timeframe': '15m',
                            'action': 'BUY',
                            'whale_threshold_usd': big_buy_events['size'].median()
                        }
                        patterns.append(pattern)
            
            return patterns
            
        except Exception as e:
            self.logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ù†Ù‡Ù†Ú¯: {e}")
            return patterns
    
    # ==================== BACKTESTING ENGINE ====================
    
    def backtest_pattern(self, pattern: Dict, df: pd.DataFrame) -> Dict:
        """ØªØ³Øª Ø§Ù„Ú¯Ùˆ Ø±ÙˆÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ§Ø±ÛŒØ®ÛŒ"""
        if 'condition' not in pattern:
            return {'success': False, 'error': 'Ø´Ø±Ø· Ø§Ù„Ú¯Ùˆ ØªØ¹Ø±ÛŒÙ Ù†Ø´Ø¯Ù‡'}
        
        try:
            # Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ø³Ø§Ø¯Ù‡ - Ø¯Ø± Ù†Ø³Ø®Ù‡ Ú©Ø§Ù…Ù„ Ø¨Ø§ÛŒØ¯ Ø¯Ù‚ÛŒÙ‚â€ŒØªØ± Ø´ÙˆØ¯
            trades = []
            initial_balance = 10000
            balance = initial_balance
            
            # ØªØ´Ø®ÛŒØµ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹ Ø§Ù„Ú¯Ùˆ
            if 'VOL_PUMP' in pattern['id']:
                # ØªØ´Ø®ÛŒØµ Ù¾Ø§Ù…Ù¾ Ø­Ø¬Ù…ÛŒ
                signals = self._detect_volume_pump_signals(df)
            elif 'WHALE_BUY' in pattern['id']:
                # ØªØ´Ø®ÛŒØµ ÙˆØ±ÙˆØ¯ Ù†Ù‡Ù†Ú¯
                signals = self._detect_whale_buy_signals(df)
            else:
                signals = []
            
            # Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ø¹Ø§Ù…Ù„Ø§Øª
            for signal in signals:
                if signal['action'] == 'BUY':
                    # ÙØ±Ø¶: Ø®Ø±ÛŒØ¯ Ø¯Ø± Ù‚ÛŒÙ…Øª Ø¨Ø³ØªÙ‡ Ø´Ø¯Ù† Ùˆ ÙØ±ÙˆØ´ 10 Ú©Ù†Ø¯Ù„ Ø¨Ø¹Ø¯
                    entry_idx = signal['index']
                    if entry_idx + 10 < len(df):
                        entry_price = df.iloc[entry_idx]['close']
                        exit_price = df.iloc[entry_idx + 10]['close']
                        
                        pnl_percent = (exit_price - entry_price) / entry_price
                        position_size = balance * 0.1  # 10% Ø³Ø±Ù…Ø§ÛŒÙ‡
                        pnl = position_size * pnl_percent
                        
                        balance += pnl
                        
                        trades.append({
                            'entry': entry_price,
                            'exit': exit_price,
                            'pnl_percent': pnl_percent,
                            'pnl_usd': pnl,
                            'timestamp': df.iloc[entry_idx]['timestamp']
                        })
            
            # ØªØ­Ù„ÛŒÙ„ Ù†ØªØ§ÛŒØ¬
            if trades:
                winning_trades = [t for t in trades if t['pnl_usd'] > 0]
                total_return = (balance - initial_balance) / initial_balance
                win_rate = len(winning_trades) / len(trades)
                
                # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø­Ø¯Ø§Ú©Ø«Ø± Ø§ÙØª Ø³Ø±Ù…Ø§ÛŒÙ‡
                equity_curve = [initial_balance]
                for trade in trades:
                    equity_curve.append(equity_curve[-1] + trade['pnl_usd'])
                
                equity_series = pd.Series(equity_curve)
                drawdown = (equity_series.expanding().max() - equity_series) / equity_series.expanding().max()
                max_drawdown = drawdown.max()
                
                return {
                    'success': True,
                    'total_trades': len(trades),
                    'winning_trades': len(winning_trades),
                    'win_rate': win_rate,
                    'total_return': total_return,
                    'max_drawdown': max_drawdown,
                    'final_balance': balance,
                    'sharpe_ratio': self._calculate_sharpe_ratio([t['pnl_percent'] for t in trades]),
                    'trades': trades[:10]  # ÙÙ‚Ø· 10 Ù…Ø¹Ø§Ù…Ù„Ù‡ Ø§ÙˆÙ„ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´
                }
            else:
                return {
                    'success': False,
                    'error': 'Ù‡ÛŒÚ† Ø³ÛŒÚ¯Ù†Ø§Ù„ÛŒ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù†Ø´Ø¯'
                }
                
        except Exception as e:
            return {'success': False, 'error': str(e)}
    
    def _detect_volume_pump_signals(self, df: pd.DataFrame) -> List[Dict]:
        """ØªØ´Ø®ÛŒØµ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ù¾Ø§Ù…Ù¾ Ø­Ø¬Ù…ÛŒ"""
        signals = []
        
        if len(df) < 50:
            return signals
        
        volume_ma = df['volume'].rolling(20).mean()
        volume_spike = df['volume'] > volume_ma * 2
        
        for i in range(len(df) - 1):
            if volume_spike.iloc[i] and df['returns'].iloc[i] > 0:
                signals.append({
                    'index': i,
                    'action': 'BUY',
                    'reason': 'volume_spike',
                    'volume_ratio': df['volume'].iloc[i] / volume_ma.iloc[i]
                })
        
        return signals
    
    # ==================== MAIN DISCOVERY PIPELINE ====================
    
    def run_full_discovery(self, symbol: str = SYMBOL) -> Dict:
        """Ø§Ø¬Ø±Ø§ÛŒ Ø®Ø· Ú©Ø§Ù…Ù„ Ú©Ø´Ù Ø§Ù„Ú¯Ùˆ"""
        self.logger.info(f"ğŸš€ Ø´Ø±ÙˆØ¹ Ú©Ø´Ù Ø§Ù„Ú¯Ùˆ Ø¨Ø±Ø§ÛŒ {symbol}")
        
        results = {
            'symbol': symbol,
            'timestamp': datetime.now().isoformat(),
            'patterns_found': [],
            'total_patterns': 0,
            'best_pattern': None,
            'status': 'running'
        }
        
        try:
            # 1. Ø§ØªØµØ§Ù„ Ø¨Ù‡ Ø¯ÛŒØªØ§Ø¨ÛŒØ³
            if not self.connect_to_database():
                results['status'] = 'db_connection_failed'
                return results
            
            # 2. Ø®ÙˆØ§Ù†Ø¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ
            price_data = self.fetch_candle_data(symbol, self.config['discovery_lookback_days'])
            whale_data = self.fetch_whale_data(symbol, self.config['discovery_lookback_days'])
            
            if len(price_data) < self.config['min_candles_for_analysis']:
                self.logger.warning("âš ï¸ Ø¯Ø§Ø¯Ù‡ Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯")
                results['status'] = 'insufficient_data'
                return results
            
            # 3. Ú©Ø´Ù Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù
            all_patterns = []
            
            # Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ù‚ÛŒÙ…Øª-Ø­Ø¬Ù…
            volume_patterns = self.discover_price_volume_patterns(price_data)
            all_patterns.extend(volume_patterns)
            
            # Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ù†Ù‡Ù†Ú¯
            if not whale_data.empty:
                whale_patterns = self.discover_whale_patterns(price_data, whale_data)
                all_patterns.extend(whale_patterns)
            
            # 4. Ø¨Ú©ØªØ³Øª Ùˆ Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ø§Ù„Ú¯ÙˆÙ‡Ø§
            validated_patterns = []
            for pattern in all_patterns:
                backtest_result = self.backtest_pattern(pattern, price_data)
                
                if backtest_result['success']:
                    pattern['backtest'] = backtest_result
                    
                    # Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ ØªØ£ÛŒÛŒØ¯
                    if (backtest_result['win_rate'] >= self.config['required_win_rate'] and
                        backtest_result['max_drawdown'] <= self.config['max_drawdown_limit']):
                        
                        pattern['validated'] = True
                        pattern['confidence'] = backtest_result['win_rate'] * 0.7 + (1 - backtest_result['max_drawdown']) * 0.3
                        validated_patterns.append(pattern)
            
            # 5. Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ùˆ Ø§Ù†ØªØ®Ø§Ø¨ Ø¨Ù‡ØªØ±ÛŒÙ† Ø§Ù„Ú¯ÙˆÙ‡Ø§
            if validated_patterns:
                validated_patterns.sort(key=lambda x: x['confidence'], reverse=True)
                results['best_pattern'] = validated_patterns[0]
            
            results['patterns_found'] = validated_patterns
            results['total_patterns'] = len(validated_patterns)
            results['status'] = 'completed'
            
            # 6. Ù†Ù…Ø§ÛŒØ´ Ù†ØªØ§ÛŒØ¬
            self.display_results(results)
            
            return results
            
        except Exception as e:
            self.logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø¬Ø±Ø§ÛŒ Ú©Ø´Ù Ø§Ù„Ú¯Ùˆ: {e}")
            results['status'] = f'error: {str(e)}'
            return results
            
        finally:
            # 7. Ù‚Ø·Ø¹ Ø§ØªØµØ§Ù„ Ø§Ø² Ø¯ÛŒØªØ§Ø¨ÛŒØ³
            self.disconnect()
    
    # ==================== UTILITIES ====================
    
    def display_results(self, results: Dict):
        """Ù†Ù…Ø§ÛŒØ´ Ù†ØªØ§ÛŒØ¬ Ú©Ø´Ù Ø§Ù„Ú¯Ùˆ"""
        print(f"""
        {'='*60}
        ğŸ¯ Ù†ØªØ§ÛŒØ¬ Ú©Ø´Ù Ø§Ù„Ú¯Ùˆ - {results['symbol']}
        {'='*60}
        
        ğŸ“Š Ø¢Ù…Ø§Ø± Ú©Ù„ÛŒ:
        â€¢ ØªØ¹Ø¯Ø§Ø¯ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ ØªØ£ÛŒÛŒØ¯Ø´Ø¯Ù‡: {results['total_patterns']}
        â€¢ ÙˆØ¶Ø¹ÛŒØª Ø§Ø¬Ø±Ø§: {results['status']}
        â€¢ Ø²Ù…Ø§Ù† ØªØ­Ù„ÛŒÙ„: {results['timestamp']}
        
        """)
        
        if results['best_pattern']:
            pattern = results['best_pattern']
            backtest = pattern.get('backtest', {})
            
            print(f"""
        ğŸ† Ø¨Ù‡ØªØ±ÛŒÙ† Ø§Ù„Ú¯Ùˆ:
        â€¢ Ø´Ù†Ø§Ø³Ù‡: {pattern.get('id', 'N/A')}
        â€¢ Ù†Ø§Ù…: {pattern.get('name', 'N/A')}
        â€¢ Ø´Ø±Ø§ÛŒØ·: {pattern.get('condition', 'N/A')}
        â€¢ Ø§Ø·Ù…ÛŒÙ†Ø§Ù†: {pattern.get('confidence', 0):.2%}
        â€¢ Ø§Ù‚Ø¯Ø§Ù…: {pattern.get('action', 'N/A')}
        
        ğŸ“ˆ Ù†ØªØ§ÛŒØ¬ Ø¨Ú©ØªØ³Øª:
        â€¢ ØªØ¹Ø¯Ø§Ø¯ Ù…Ø¹Ø§Ù…Ù„Ø§Øª: {backtest.get('total_trades', 0)}
        â€¢ Ù†Ø±Ø® Ø¨Ø±Ø¯: {backtest.get('win_rate', 0):.2%}
        â€¢ Ø¨Ø§Ø²Ø¯Ù‡ Ú©Ù„: {backtest.get('total_return', 0):.2%}
        â€¢ Ø­Ø¯Ø§Ú©Ø«Ø± Ø§ÙØª: {backtest.get('max_drawdown', 0):.2%}
        """)
        
        print(f"{'='*60}")
    
    def _calculate_sharpe_ratio(self, returns: List[float]) -> float:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù†Ø³Ø¨Øª Ø´Ø§Ø±Ù¾"""
        if not returns or np.std(returns) == 0:
            return 0.0
        return np.mean(returns) / np.std(returns) * np.sqrt(365 * 24 * 60)  # Ø³Ø§Ù„ÛŒØ§Ù†Ù‡â€ŒØ´Ø¯Ù‡
    
    def save_patterns_to_file(self, patterns: List[Dict], filename: str = "discovered_patterns.json"):
        """Ø°Ø®ÛŒØ±Ù‡ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ú©Ø´Ùâ€ŒØ´Ø¯Ù‡ Ø¯Ø± ÙØ§ÛŒÙ„"""
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(patterns, f, indent=2, ensure_ascii=False, default=str)
            self.logger.info(f"ğŸ’¾ Ø§Ù„Ú¯ÙˆÙ‡Ø§ Ø¯Ø± {filename} Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù†Ø¯")
        except Exception as e:
            self.logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ Ø§Ù„Ú¯ÙˆÙ‡Ø§: {e}")

# ==================== EXECUTION ====================

if __name__ == "__main__":
    print("""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘        ğŸ§  Ù…ÙˆØªÙˆØ± Ú©Ø´Ù Ø§Ù„Ú¯Ùˆ - Ù†Ø³Ø®Ù‡ ØªÙˆÙ„ÛŒØ¯                   â•‘
    â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
    â•‘ Ø§ØªØµØ§Ù„ Ù…Ø³ØªÙ‚ÛŒÙ… Ø¨Ù‡ Ø¯ÛŒØªØ§Ø¨ÛŒØ³ ÙˆØ§Ù‚Ø¹ÛŒ                           â•‘
    â•‘ Ú©Ø´Ù Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ù‚ÛŒÙ…ØªØŒ Ø­Ø¬Ù… Ùˆ Ù†Ù‡Ù†Ú¯                           â•‘
    â•‘ Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ø®ÙˆØ¯Ú©Ø§Ø± Ø¨Ø§ Ø¨Ú©ØªØ³Øª                              â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    # Ø³Ø§Ø®Øª Ù…ÙˆØªÙˆØ±
    engine = RealDataPatternEngine()
    
    # Ø§Ø¬Ø±Ø§ÛŒ Ú©Ø´Ù Ø§Ù„Ú¯Ùˆ
    results = engine.run_full_discovery(SYMBOL)
    
    # Ø°Ø®ÛŒØ±Ù‡ Ù†ØªØ§ÛŒØ¬
    if results['patterns_found']:
        engine.save_patterns_to_file(results['patterns_found'])
```